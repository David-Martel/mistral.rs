2bcf0e9e3 Fix overcounting on nonmapped params in device mapping (#1721)
43531ee5e Remove erroneous debug
db6d43956 Respect silent setting in progress bar (#1720)
07ff277cb Add custom logging example (#1719)
ddc63cef1 Docs: Add GPU architecture compatibility table for FlashAttention (#1712)
084b39b03 Cuda clippy fixes (#1709)
dcd2c7a07 Fix server hang with mcp (#1706)
6d845753e Fixes for qwen 2.5 (#1708)
b0326ff7a Fix auto loader confusion (#1707)
2b7dd90d4 Fix embedding inputs processor in search + flash attn case (#1705)
f788be344 Fix flash attn on cuda 13.0 build (#1704)
542aafde8 Refactor search embedding to use EmbeddingGemma (#1698)
bd2bc35d0 Support cuda 13.0! (#1697)
fedf2b032 Expose max seqlen api on Engine (#1695)
246b44af5 Add example for batching in embedding models (#1694)
ec1563c0f Ensure paged attn is disabled for embedding models (#1693)
e03d3526d Remove `once_cell` dependency from multiple crates for improved performance and consistency. (#1691)
c98198c21 Fixes for qwen 2.5 vl (#1690)
3ad0cc7a4 Fix apply chat template tool call case (#1689)
230e9c7c6 Implement Qwen 3 Embedding (#1686)
81fbcdcc5 Tweak readme supported models
a3d3d473f Support embedding models: EmbeddingGemma (#1684)
ab3f93934 Temporarily disable fast sampler (#1685)
0a2d329aa Revamped topology system with improved flexibility (#1683)
c3d69e0e4 Correctly handle tied embeddings in qwen3_vl config (#1682)
fd7c5473b Slightly faster mistralrs-vision normalize path (#1681)
308e1cdee Fix panic in prompt token truncation logic (#1678)
48cf293ad Fix inverted logic bug in DRY sampler sequence breaker encoding (#1679)
b64d86bcf Fix hang and performance drop with Metal (#1662)
8b262783c no ram limits for CPU (#1675)
bc0384ba9 Fix gemma3 example (#1674)
bde5f3e67 Remove restriction on qwen vl batch size (#1673)
0410d162c Fix cpu flash attn mask case (#1672)
60f33d34e Refactor flash attn dispatch to better handle CPU (#1671)
530463af1 Implement Qwen 3 VL! (#1657)
5a3648a17 Include stubs in maturin source builds (#1656)
65faf59df No busyloop refactor (#1655)
d101c5fce Refactor/simplify paged attn modules (#1654)
a9b50d2d4 Handle case where gemma 3n q != (k=v) devices (#1653)
b9974565b Patch clippy
242c6b703 Patch clippy
7a7883a26 Audio processing functions have been added: normalize, apply_fade, and remove_dc_offset. These functions are used to prevent audio distortion and enhance sound quality. Additionally, tests have been added for these functions. (#1572)
a92deee82 Handle cpu dtype requirements for conv (#1650)
a13220255 Updated candle dep
6a26628a3 Drain dummy run reciever to fix sender dropping (#1645)
764aba567 Bump candle dep, add no prefix cache api to vision model
